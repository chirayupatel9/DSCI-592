{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ResNet50-based model for material property prediction.\n",
    "This module implements a ResNet50-based model for predicting material properties.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_least_utilized_gpu():\n",
    "    \"\"\"Get the GPU with the least memory usage.\"\"\"\n",
    "    try:\n",
    "        # Run nvidia-smi to get GPU memory usage\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'],\n",
    "                              capture_output=True, text=True)\n",
    "        memory_usage = [int(x) for x in result.stdout.strip().split('\\n')]\n",
    "        \n",
    "        # Find GPU with minimum memory usage\n",
    "        min_usage = min(memory_usage)\n",
    "        gpu_id = memory_usage.index(min_usage)\n",
    "        \n",
    "        print(f\"Selected GPU {gpu_id} with {min_usage}MB memory usage\")\n",
    "        return gpu_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting GPU usage: {e}\")\n",
    "        return 0  # Fallback to GPU 0 if there's an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MaterialDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "    \n",
    "class MaterialPropertyMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super(MaterialPropertyMLP, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "class ResNet50Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super(ResNet50Model, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Modify the first layer to accept our input dimension\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Modify the final layer for our regression task\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Reshape input to match ResNet50's expected input shape\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, 1, -1, 1)  # Reshape to [batch_size, 1, features, 1]\n",
    "        x = x.expand(-1, 1, -1, 224)  # Expand to match ResNet50's expected size\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_resnet50(X_train, X_test, y_train, y_test, target='band_gap', \n",
    "                  batch_size=32, num_epochs=50, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Train a ResNet50-based model for material property prediction.\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test: Training and testing features\n",
    "        y_train, y_test: Training and testing targets\n",
    "        target: Target property name\n",
    "        batch_size: Batch size for training\n",
    "        num_epochs: Number of training epochs\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \"\"\"\n",
    "    # Select the least utilized GPU\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"backend:cudaMallocAsync\"\n",
    "\n",
    "    gpu_id = get_least_utilized_gpu()\n",
    "    device = torch.device(f'cuda:{gpu_id}')\n",
    "    print(f\"Using GPU {gpu_id} for training\")\n",
    "    torch.cuda.empty_cache()\n",
    "    # Create datasets\n",
    "    train_dataset = MaterialDataset(X_train, y_train)\n",
    "    test_dataset = MaterialDataset(X_test, y_test)\n",
    "    \n",
    "    # Create data loaders with multiple workers\n",
    "    num_workers = 8#min(4, os.cpu_count() or 1)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                            num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                           num_workers=num_workers, pin_memory=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ResNet50Model(input_dim=X_train.shape[1])\n",
    "    #model = MaterialPropertyMLP(input_dim=X_train.shape[1])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # Create progress bar for epochs\n",
    "    epoch_pbar = tqdm(range(num_epochs), desc=\"Training Progress\")\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        # Create progress bar for batches\n",
    "        batch_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        for inputs, targets in batch_pbar:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            print(torch.cuda.memory_summary())\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            batch_pbar.set_postfix({'batch_loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                test_loss += criterion(outputs, targets).item()\n",
    "        \n",
    "        test_loss = test_loss / len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        # Update epoch progress bar\n",
    "        epoch_pbar.set_postfix({\n",
    "            'train_loss': f'{train_loss:.4f}',\n",
    "            'test_loss': f'{test_loss:.4f}'\n",
    "        })\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f'models/resnet50_{target}.pth')\n",
    "    \n",
    "    return model, train_losses, test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_resnet50(model, X):\n",
    "    \"\"\"\n",
    "    Make predictions using the trained ResNet50 model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained ResNet50 model\n",
    "        X: Input features\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    gpu_id = get_least_utilized_gpu()\n",
    "    device = torch.device(f'cuda:{gpu_id}')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        X = torch.FloatTensor(X).to(device)\n",
    "        predictions = model(X)\n",
    "    \n",
    "    return predictions.cpu().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to train the ResNet50 model for material property prediction.\n",
    "This script uses the existing data preprocessing pipeline and trains the ResNet50 model.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from resnet50_model import train_resnet50, predict_resnet50\n",
    "import joblib\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_elements_to_features(elements_str):\n",
    "    \"\"\"Convert elements string into numeric features\"\"\"\n",
    "    # Split elements and count occurrences\n",
    "    elements = elements_str.split(',')\n",
    "    element_counts = Counter(elements)\n",
    "    \n",
    "    # Create a dictionary of element counts\n",
    "    features = {}\n",
    "    for element in element_counts:\n",
    "        features[f'element_{element}'] = element_counts[element]\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_preprocess_data(target='band_gap'):\n",
    "    \"\"\"Load and preprocess data for ResNet50 model\"\"\"\n",
    "    # Load data\n",
    "    df = pd.read_csv(\"materials_for_ml.csv\")\n",
    "    \n",
    "    # Drop rows with missing target values\n",
    "    df = df.dropna(subset=[target])\n",
    "    \n",
    "    # Convert elements to numeric features\n",
    "    element_features = pd.DataFrame([convert_elements_to_features(elem) for elem in df['formula']])\n",
    "    element_features = element_features.fillna(0)  # Fill NaN with 0 for elements not present\n",
    "    \n",
    "    # Select features\n",
    "    categorical_cols = [\"crystal_system\"]\n",
    "    element_cols = [col for col in df.columns if col.startswith('contains_')]\n",
    "    numerical_cols = [col for col in df.columns if col not in categorical_cols + element_cols + [target, 'material_id', 'formula']]\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    df = pd.get_dummies(df, columns=categorical_cols)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df.drop(columns=[target, 'material_id', 'formula'])\n",
    "    \n",
    "    # Combine original features with element features\n",
    "    X = pd.concat([X, element_features], axis=1)\n",
    "    \n",
    "    y = df[target]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Save the scaler\n",
    "    joblib.dump(scaler, f'models/resnet50_{target}_scaler.pkl')\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train.values, y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_training_history(train_losses, test_losses, target):\n",
    "    \"\"\"Plot training and validation loss history\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(test_losses, label='Validation Loss')\n",
    "    plt.title(f'ResNet50 Training History - {target}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'plots/resnet50_{target}_training_history.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # Target properties to predict\n",
    "    targets = ['band_gap', 'formation_energy_per_atom']  # Add more targets as needed\n",
    "    \n",
    "    for target in targets:\n",
    "        print(f\"\\nTraining ResNet50 model for {target}...\")\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        X_train, X_test, y_train, y_test = load_and_preprocess_data(target)\n",
    "        \n",
    "        # Train model\n",
    "        model, train_losses, test_losses = train_resnet50(\n",
    "            X_train, X_test, y_train, y_test,\n",
    "            target=target,\n",
    "            batch_size=32,\n",
    "            num_epochs=5,\n",
    "            learning_rate=0.001\n",
    "        )\n",
    "        \n",
    "        # Plot training history\n",
    "        plot_training_history(train_losses, test_losses, target)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = predict_resnet50(model, X_test)\n",
    "        \n",
    "        # Calculate and print metrics\n",
    "        mse = np.mean((y_test - y_pred) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = np.mean(np.abs(y_test - y_pred))\n",
    "        \n",
    "        print(f\"\\nResults for {target}:\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
